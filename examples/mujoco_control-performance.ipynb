{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ilqr import iLQR\n",
    "import gym\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "from aprl.agents import MujocoFiniteDiffDynamicsBasic, MujocoFiniteDiffDynamicsPerformance, MujocoFiniteDiffCost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Environment setup\n",
    "env = gym.make('Reacher-v2').unwrapped\n",
    "env.frame_skip = 1\n",
    "env.seed(42)\n",
    "_obs = env.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Planning setup\n",
    "N = 100  # planning horizon\n",
    "us_init = np.array([env.action_space.sample() for _ in range(N)])\n",
    "\n",
    "dynamics = {\n",
    "    # Uses env.step(u) directly and finite difference on qpos and qvel directly.\n",
    "    'my_basic': MujocoFiniteDiffDynamicsBasic(env),\n",
    "    # Sets ctrl to u directly then uses MuJoCo's forwardSkip to compute qacc.\n",
    "    # Computes finite difference on qacc, then estimates derivative of qpos and qvel.\n",
    "    'my_performance': MujocoFiniteDiffDynamicsPerformance(env),\n",
    "}\n",
    "x0s = {k: dyn.get_state() for k, dyn in dynamics.items()}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Finite difference cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "finite_cost = MujocoFiniteDiffCost(env)\n",
    "finite_ilqr = iLQR(dynamics, finite_cost, N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "finite_xs, finite_us = finite_ilqr.fit(x0, us_init, n_iterations=100, on_iteration=on_iteration)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analytic cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import theano\n",
    "from theano import tensor as T\n",
    "from ilqr.cost import AutoDiffCost\n",
    "\n",
    "# Reacher, Gym observation:\n",
    "# obs[0:1]: xs; np.cos(qpos[0:2]) (qpos[0] is joint0, qpos[1] is joint1)\n",
    "# obs[2:3]: ys; np.sin(qpos[0:2]);\n",
    "# obs[4:5]: goal x and y; qpos[2:]; (target_x and target_y)\n",
    "# obs[6:7]: theta dot\n",
    "# obs[8:9]: xy of fingertip - target\n",
    "\n",
    "def make_reacher_cost(kind, control_weight=1.0):\n",
    "    # qpos[0:3]: theta of joint 0, theta of joint 1; target x and y.\n",
    "    qpos_inputs = [T.dscalar('theta'), T.dscalar('phi'), T.dscalar('targetx'), T.dscalar('targety')]\n",
    "    # qvel: derivatives of the above; note target x and y are constant so have derivative zero.\n",
    "    qvel_inputs = [T.dscalar('thetadot'), T.dscalar('phidot'), T.dscalar('_zero1'), T.dscalar('_zero2')]\n",
    "    # qacc: second derivatives of qpos. We don't actually use these in the cost.\n",
    "    qacc_inputs = [T.dscalar('_acc{}'.format(i)) for i in range(len(qpos_inputs))]\n",
    "    # qacc_warmstart: same shape as qacc\n",
    "    qacc_warmstart_inputs = [T.dscalar('_accwarm{}'.format(i)) for i in range(len(qpos_inputs))]\n",
    "    # qfrc_applied: same shape as qacc\n",
    "    qfrc_applied_inputs = [T.dscalar('_qfrc_applied{}'.format(i)) for i in range(len(qpos_inputs))]\n",
    "    # xfrc_applied: (5,6)\n",
    "    xfrc_applied_inputs = [T.dscalar('_xfrc_applied{}'.format(i)) for i in range(5 * 6)]\n",
    "    if kind == 'mujoco_py':\n",
    "        # Reacher, MJSimState.flatten():\n",
    "        # obs[0]: time step, obs[1:4]: qpos[0:3]; obs[5:8]: qvel[0:3]\n",
    "        # In general might include action and udd_state, but not for Reacher.\n",
    "        x_inputs = [T.dscalar('_time')] + qpos_inputs + qvel_inputs\n",
    "    elif kind == 'my_all':\n",
    "        # Reacher, MujocoRelevantState.flatten()\n",
    "        x_inputs = qpos_inputs + qvel_inputs + qacc_inputs + qacc_warmstart_inputs + qfrc_applied_inputs + xfrc_applied_inputs\n",
    "    elif kind == 'my_recommended':\n",
    "        x_inputs = qpos_inputs + qvel_inputs + qacc_inputs + qacc_warmstart_inputs\n",
    "    elif kind == 'my_basic_plus':\n",
    "        x_inputs = qpos_inputs + qvel_inputs + qacc_inputs\n",
    "    elif kind in ['my_basic', 'my_warmstart', 'my_performance']:\n",
    "        x_inputs = qpos_inputs + qvel_inputs\n",
    "    else:\n",
    "        raise ValueError(\"Unrecognised kind: '{}'\".format(kind))\n",
    "    u_inputs = [T.dscalar('thetadotdot'), T.dscalar('phidotdot')]\n",
    "    qpos = T.stack(qpos_inputs)\n",
    "    u = T.stack(u_inputs)\n",
    "    \n",
    "    control_cost = T.dot(u, u)\n",
    "    target_xpos = qpos[2:4]\n",
    "    body1_xpos = 0.1 * T.stack([T.cos(qpos[0]), T.sin(qpos[0])])\n",
    "    fingertip_xpos_delta = 0.11 * T.stack([T.cos(qpos[1]), T.sin(qpos[1])])\n",
    "    fingertip_xpos = body1_xpos + fingertip_xpos_delta\n",
    "    delta = fingertip_xpos - target_xpos\n",
    "    state_cost = T.sqrt(T.dot(delta, delta))\n",
    "    l = state_cost + control_weight * control_cost\n",
    "    l_terminal = T.zeros(())\n",
    "    return AutoDiffCost(l, l_terminal, x_inputs, u_inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['my_basic', 'my_performance'])\n",
      "*** Fitting my_basic ***\n",
      "iteration -1 converged 77.0672963001787 [ 2.32864069 -1.19993367  0.02243766  0.07369059  3.22880925 -4.04084829\n",
      "  0.          0.        ]\n",
      "iteration 0 accepted 16.85489457400974 [ 2.6949496  -0.24070435  0.02243766  0.07369059  3.40360537 -3.92220608\n",
      "  0.          0.        ]\n",
      "iteration 1 accepted 13.977863492838418 [ 2.84173297  0.20747149  0.02243766  0.07369059  3.52506559 -3.71466247\n",
      "  0.          0.        ]\n",
      "iteration 2 accepted 12.170881768875319 [ 2.85318372 -0.05022272  0.02243766  0.07369059  3.6027983  -3.36014486\n",
      "  0.          0.        ]\n",
      "iteration 3 failed 12.170881768875327 [ 2.85318372 -0.05022272  0.02243766  0.07369059  3.6027983  -3.36014486\n",
      "  0.          0.        ]\n",
      "iteration 4 accepted 12.129830429913762 [ 2.75884007  0.05266829  0.02243766  0.07369059  3.51072004 -3.25887641\n",
      "  0.          0.        ]\n",
      "iteration 5 accepted 12.124607048985949 [ 2.56258972  0.37131624  0.02243766  0.07369059  3.39298188 -3.05937864\n",
      "  0.          0.        ]\n",
      "iteration 6 accepted 11.490801860765021 [ 1.67595467  1.59491991  0.02243766  0.07369059  2.3768545  -2.37265483\n",
      "  0.          0.        ]\n",
      "iteration 7 accepted 11.342931199313098 [ 1.54615913  0.89666666  0.02243766  0.07369059  2.68020633 -3.12451684\n",
      "  0.          0.        ]\n",
      "iteration 8 accepted 11.09716013975501 [ 2.62886218  0.0583162   0.02243766  0.07369059  7.89672952 -7.57047852\n",
      "  0.          0.        ]\n",
      "iteration 9 accepted 11.00091227405011 [ 2.62607726  0.17891349  0.02243766  0.07369059  7.61959307 -6.61151237\n",
      "  0.          0.        ]\n",
      "iteration 10 accepted 10.989199192821237 [ 2.57160303  0.14481008  0.02243766  0.07369059  7.37118335 -6.75281153\n",
      "  0.          0.        ]\n",
      "iteration 11 accepted 10.988909826330259 [ 2.57239721  0.14035424  0.02243766  0.07369059  7.34354135 -6.75868878\n",
      "  0.          0.        ]\n",
      "iteration 12 converged 10.988909492516136 [ 2.5725093   0.14033211  0.02243766  0.07369059  7.34337537 -6.75902724\n",
      "  0.          0.        ]\n",
      "*** Fitted my_basic in 8.239380121231079s ***\n",
      "*** Fitting my_performance ***\n",
      "iteration -1 converged 77.0672963001787 [ 2.32864069 -1.19993367  0.02243766  0.07369059  3.22880925 -4.04084829\n",
      "  0.          0.        ]\n",
      "iteration 0 accepted 16.94613430030612 [ 2.68659913 -0.26476577  0.02243766  0.07369059  3.39948363 -3.92047971\n",
      "  0.          0.        ]\n",
      "iteration 1 accepted 13.909381585042354 [ 2.86071336  0.20237406  0.02243766  0.07369059  3.51394958 -3.70692028\n",
      "  0.          0.        ]\n",
      "iteration 2 accepted 11.779144674683623 [ 2.78632897  0.01191648  0.02243766  0.07369059  3.71653276 -3.51062816\n",
      "  0.          0.        ]\n",
      "iteration 3 failed 11.779144674683616 [ 2.78632897  0.01191648  0.02243766  0.07369059  3.71653276 -3.51062816\n",
      "  0.          0.        ]\n",
      "iteration 4 accepted 11.751433840348295 [ 2.78685149  0.09948017  0.02243766  0.07369059  3.71014416 -3.43177674\n",
      "  0.          0.        ]\n",
      "iteration 5 accepted 11.748124455167973 [ 2.76860303  0.10263131  0.02243766  0.07369059  3.69566749 -3.42763914\n",
      "  0.          0.        ]\n",
      "iteration 6 failed 11.748124455167979 [ 2.76860303  0.10263131  0.02243766  0.07369059  3.69566749 -3.42763914\n",
      "  0.          0.        ]\n",
      "iteration 7 failed 11.748124455167979 [ 2.76860303  0.10263131  0.02243766  0.07369059  3.69566749 -3.42763914\n",
      "  0.          0.        ]\n",
      "iteration 8 accepted 11.747177556081796 [ 2.7026955   0.14273054  0.02243766  0.07369059  3.64295859 -3.38872009\n",
      "  0.          0.        ]\n",
      "iteration 9 accepted 11.746268233809861 [ 2.69045557  0.14980445  0.02243766  0.07369059  3.65423942 -3.39126882\n",
      "  0.          0.        ]\n",
      "iteration 10 failed 11.746268233809857 [ 2.69045557  0.14980445  0.02243766  0.07369059  3.65423942 -3.39126882\n",
      "  0.          0.        ]\n",
      "iteration 11 failed 11.746268233809857 [ 2.69045557  0.14980445  0.02243766  0.07369059  3.65423942 -3.39126882\n",
      "  0.          0.        ]\n",
      "iteration 12 accepted 11.691023614339256 [ 2.55982585  0.18533902  0.02243766  0.07369059  6.32163245 -6.52547045\n",
      "  0.          0.        ]\n",
      "iteration 13 accepted 11.580738100784481 [ 2.50308098  0.15028797  0.02243766  0.07369059  6.91058952 -6.32390229\n",
      "  0.          0.        ]\n",
      "iteration 14 accepted 11.013191881769282 [ 2.43633763  0.52469174  0.02243766  0.07369059  6.9178786  -6.11517197\n",
      "  0.          0.        ]\n",
      "iteration 15 accepted 10.99324238355724 [ 2.55733891  0.09805935  0.02243766  0.07369059  7.30872196 -6.91489989\n",
      "  0.          0.        ]\n",
      "iteration 16 accepted 10.987777649566413 [ 2.50327448  0.16738342  0.02243766  0.07369059  7.14093764 -6.69881562\n",
      "  0.          0.        ]\n",
      "iteration 17 accepted 10.98766585377284 [ 2.50062359  0.17004765  0.02243766  0.07369059  7.13266978 -6.6901594\n",
      "  0.          0.        ]\n",
      "iteration 18 accepted 10.987638222558077 [ 2.49936046  0.17120824  0.02243766  0.07369059  7.12905199 -6.68672527\n",
      "  0.          0.        ]\n",
      "iteration 19 accepted 10.987623689207684 [ 2.49741231  0.1729394   0.02243766  0.07369059  7.12364304 -6.68180027\n",
      "  0.          0.        ]\n",
      "iteration 20 failed 10.98762368920768 [ 2.49741231  0.1729394   0.02243766  0.07369059  7.12364304 -6.68180027\n",
      "  0.          0.        ]\n",
      "iteration 21 failed 10.98762368920768 [ 2.49741231  0.1729394   0.02243766  0.07369059  7.12364304 -6.68180027\n",
      "  0.          0.        ]\n",
      "iteration 22 failed 10.98762368920768 [ 2.49741231  0.1729394   0.02243766  0.07369059  7.12364304 -6.68180027\n",
      "  0.          0.        ]\n",
      "iteration 23 failed 10.98762368920768 [ 2.49741231  0.1729394   0.02243766  0.07369059  7.12364304 -6.68180027\n",
      "  0.          0.        ]\n",
      "iteration 24 failed 10.98762368920768 [ 2.49741231  0.1729394   0.02243766  0.07369059  7.12364304 -6.68180027\n",
      "  0.          0.        ]\n",
      "iteration 25 accepted 10.987373660776766 [ 2.48879368  0.18213839  0.02243766  0.07369059  7.09874492 -6.65476521\n",
      "  0.          0.        ]\n",
      "iteration 26 failed 10.987373660776765 [ 2.48879368  0.18213839  0.02243766  0.07369059  7.09874492 -6.65476521\n",
      "  0.          0.        ]\n",
      "iteration 27 failed 10.987373660776765 [ 2.48879368  0.18213839  0.02243766  0.07369059  7.09874492 -6.65476521\n",
      "  0.          0.        ]\n",
      "iteration 28 failed 10.987373660776765 [ 2.48879368  0.18213839  0.02243766  0.07369059  7.09874492 -6.65476521\n",
      "  0.          0.        ]\n",
      "iteration 29 accepted 10.978426212614751 [ 2.44080685  0.22826803  0.02243766  0.07369059  7.09378431 -6.648596\n",
      "  0.          0.        ]\n",
      "iteration 30 accepted 10.215208981107168 [ 1.23818832  1.16162066  0.02243766  0.07369059  6.34020376 -5.9063056\n",
      "  0.          0.        ]\n",
      "iteration 31 accepted 9.921198982855195 [-0.11379165  2.65209911  0.02243766  0.07369059  3.26599413 -3.06647603\n",
      "  0.          0.        ]\n",
      "iteration 32 failed 9.921198982855193 [-0.11379165  2.65209911  0.02243766  0.07369059  3.26599413 -3.06647603\n",
      "  0.          0.        ]\n",
      "iteration 33 failed 9.921198982855193 [-0.11379165  2.65209911  0.02243766  0.07369059  3.26599413 -3.06647603\n",
      "  0.          0.        ]\n",
      "iteration 34 failed 9.921198982855193 [-0.11379165  2.65209911  0.02243766  0.07369059  3.26599413 -3.06647603\n",
      "  0.          0.        ]\n",
      "iteration 35 accepted 8.292456556401298 [ 0.09132855  1.8297117   0.02243766  0.07369059  3.0407027  -2.88347845\n",
      "  0.          0.        ]\n",
      "iteration 36 accepted 8.211971521228602 [ 0.42287914  2.20689198  0.02243766  0.07369059  2.92575066 -2.15945618\n",
      "  0.          0.        ]\n",
      "iteration 37 accepted 7.634896464430895 [ 0.288883    2.34114642  0.02243766  0.07369059  2.72898358 -2.01208293\n",
      "  0.          0.        ]\n",
      "iteration 38 accepted 7.561949675709692 [-0.16112812  2.15732812  0.02243766  0.07369059  1.55061528 -1.95131389\n",
      "  0.          0.        ]\n",
      "iteration 39 accepted 7.553142370259808 [-0.1551002   2.27453147  0.02243766  0.07369059  1.6035493  -1.70507696\n",
      "  0.          0.        ]\n",
      "iteration 40 failed 7.553142370259807 [-0.1551002   2.27453147  0.02243766  0.07369059  1.6035493  -1.70507696\n",
      "  0.          0.        ]\n",
      "iteration 41 failed 7.553142370259807 [-0.1551002   2.27453147  0.02243766  0.07369059  1.6035493  -1.70507696\n",
      "  0.          0.        ]\n",
      "iteration 42 failed 7.553142370259807 [-0.1551002   2.27453147  0.02243766  0.07369059  1.6035493  -1.70507696\n",
      "  0.          0.        ]\n",
      "iteration 43 failed 7.553142370259807 [-0.1551002   2.27453147  0.02243766  0.07369059  1.6035493  -1.70507696\n",
      "  0.          0.        ]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 44 accepted 7.553103912646529 [-0.15547401  2.27696798  0.02243766  0.07369059  1.6043329  -1.70183766\n",
      "  0.          0.        ]\n",
      "iteration 45 failed 7.553103912646528 [-0.15547401  2.27696798  0.02243766  0.07369059  1.6043329  -1.70183766\n",
      "  0.          0.        ]\n",
      "iteration 46 failed 7.553103912646528 [-0.15547401  2.27696798  0.02243766  0.07369059  1.6043329  -1.70183766\n",
      "  0.          0.        ]\n",
      "iteration 47 accepted 7.552928529182998 [-0.15664361  2.28831727  0.02243766  0.07369059  1.60988271 -1.68860811\n",
      "  0.          0.        ]\n",
      "iteration 48 failed 7.552928529183002 [-0.15664361  2.28831727  0.02243766  0.07369059  1.60988271 -1.68860811\n",
      "  0.          0.        ]\n",
      "iteration 49 failed 7.552928529183002 [-0.15664361  2.28831727  0.02243766  0.07369059  1.60988271 -1.68860811\n",
      "  0.          0.        ]\n",
      "iteration 50 accepted 7.551963435468378 [-0.1568755   2.29686283  0.02243766  0.07369059  1.6168613  -1.68131666\n",
      "  0.          0.        ]\n",
      "iteration 51 failed 7.5519634354683784 [-0.1568755   2.29686283  0.02243766  0.07369059  1.6168613  -1.68131666\n",
      "  0.          0.        ]\n",
      "iteration 52 accepted 7.551527734493916 [-0.15678064  2.30437059  0.02243766  0.07369059  1.62445595 -1.67567703\n",
      "  0.          0.        ]\n",
      "iteration 53 failed 7.5515277344939165 [-0.15678064  2.30437059  0.02243766  0.07369059  1.62445595 -1.67567703\n",
      "  0.          0.        ]\n",
      "iteration 54 accepted 7.55136062171389 [-0.15640149  2.31094494  0.02243766  0.07369059  1.6325651  -1.67150747\n",
      "  0.          0.        ]\n",
      "iteration 55 failed 7.551360621713889 [-0.15640149  2.31094494  0.02243766  0.07369059  1.6325651  -1.67150747\n",
      "  0.          0.        ]\n",
      "iteration 56 accepted 7.551180556267262 [-0.15577708  2.31661568  0.02243766  0.07369059  1.64111722 -1.66876969\n",
      "  0.          0.        ]\n",
      "iteration 57 failed 7.551180556267265 [-0.15577708  2.31661568  0.02243766  0.07369059  1.64111722 -1.66876969\n",
      "  0.          0.        ]\n",
      "iteration 58 accepted 7.509497995339222 [ 0.11002591  2.26374384  0.02243766  0.07369059  2.30279439 -2.1068049\n",
      "  0.          0.        ]\n",
      "iteration 59 accepted 7.235827494023024 [ 0.1948589   2.09306975  0.02243766  0.07369059  2.36138191 -2.26035867\n",
      "  0.          0.        ]\n",
      "iteration 60 accepted 7.234513416088322 [ 0.19667068  2.0904982   0.02243766  0.07369059  2.35772367 -2.25154828\n",
      "  0.          0.        ]\n",
      "iteration 61 accepted 7.229109453019332 [ 0.17578443  2.22518891  0.02243766  0.07369059  2.31482167 -1.96899274\n",
      "  0.          0.        ]\n",
      "iteration 62 accepted 7.186824697609893 [ 0.18407736  2.17252317  0.02243766  0.07369059  2.30035789 -2.02557422\n",
      "  0.          0.        ]\n",
      "iteration 63 accepted 7.183251162468545 [ 0.1853304   2.16147153  0.02243766  0.07369059  2.29457123 -2.03488985\n",
      "  0.          0.        ]\n",
      "iteration 64 accepted 7.182426281828665 [ 0.18632642  2.1507206   0.02243766  0.07369059  2.28800858 -2.04302441\n",
      "  0.          0.        ]\n",
      "iteration 65 failed 7.182426281828668 [ 0.18632642  2.1507206   0.02243766  0.07369059  2.28800858 -2.04302441\n",
      "  0.          0.        ]\n",
      "iteration 66 failed 7.182426281828668 [ 0.18632642  2.1507206   0.02243766  0.07369059  2.28800858 -2.04302441\n",
      "  0.          0.        ]\n",
      "iteration 67 failed 7.182426281828668 [ 0.18632642  2.1507206   0.02243766  0.07369059  2.28800858 -2.04302441\n",
      "  0.          0.        ]\n",
      "iteration 68 failed 7.182426281828668 [ 0.18632642  2.1507206   0.02243766  0.07369059  2.28800858 -2.04302441\n",
      "  0.          0.        ]\n",
      "iteration 69 failed 7.182426281828668 [ 0.18632642  2.1507206   0.02243766  0.07369059  2.28800858 -2.04302441\n",
      "  0.          0.        ]\n",
      "iteration 70 accepted 7.1823433852358125 [ 0.18651315  2.14904207  0.02243766  0.07369059  2.28685423 -2.04399214\n",
      "  0.          0.        ]\n",
      "iteration 71 failed 7.1823433852358125 [ 0.18651315  2.14904207  0.02243766  0.07369059  2.28685423 -2.04399214\n",
      "  0.          0.        ]\n",
      "iteration 72 failed 7.1823433852358125 [ 0.18651315  2.14904207  0.02243766  0.07369059  2.28685423 -2.04399214\n",
      "  0.          0.        ]\n",
      "iteration 73 accepted 7.182246771952896 [ 0.18676836  2.14762761  0.02243766  0.07369059  2.28615242 -2.04483574\n",
      "  0.          0.        ]\n",
      "iteration 74 failed 7.182246771952899 [ 0.18676836  2.14762761  0.02243766  0.07369059  2.28615242 -2.04483574\n",
      "  0.          0.        ]\n",
      "iteration 75 accepted 7.182235640468254 [ 0.18700594  2.14620683  0.02243766  0.07369059  2.28540992 -2.04569877\n",
      "  0.          0.        ]\n",
      "iteration 76 failed 7.182235640468252 [ 0.18700594  2.14620683  0.02243766  0.07369059  2.28540992 -2.04569877\n",
      "  0.          0.        ]\n",
      "iteration 77 failed 7.182235640468252 [ 0.18700594  2.14620683  0.02243766  0.07369059  2.28540992 -2.04569877\n",
      "  0.          0.        ]\n",
      "iteration 78 accepted 7.1820550045396425 [ 0.18832799  2.14066385  0.02243766  0.07369059  2.28318904 -2.04869969\n",
      "  0.          0.        ]\n",
      "iteration 79 failed 7.1820550045396425 [ 0.18832799  2.14066385  0.02243766  0.07369059  2.28318904 -2.04869969\n",
      "  0.          0.        ]\n",
      "iteration 80 failed 7.1820550045396425 [ 0.18832799  2.14066385  0.02243766  0.07369059  2.28318904 -2.04869969\n",
      "  0.          0.        ]\n",
      "iteration 81 accepted 7.15974728004999 [ 0.10462528  2.20404056  0.02243766  0.07369059  2.21001585 -1.97973569\n",
      "  0.          0.        ]\n",
      "iteration 82 accepted 7.085179060722754 [ 0.09264417  2.24727933  0.02243766  0.07369059  2.19588707 -1.9341218\n",
      "  0.          0.        ]\n",
      "iteration 83 accepted 7.084830233182628 [ 0.08870701  2.27601389  0.02243766  0.07369059  2.18613991 -1.90661565\n",
      "  0.          0.        ]\n",
      "iteration 84 failed 7.0848302331826325 [ 0.08870701  2.27601389  0.02243766  0.07369059  2.18613991 -1.90661565\n",
      "  0.          0.        ]\n",
      "iteration 85 failed 7.0848302331826325 [ 0.08870701  2.27601389  0.02243766  0.07369059  2.18613991 -1.90661565\n",
      "  0.          0.        ]\n",
      "iteration 86 failed 7.0848302331826325 [ 0.08870701  2.27601389  0.02243766  0.07369059  2.18613991 -1.90661565\n",
      "  0.          0.        ]\n",
      "iteration 87 accepted 7.0018368299440175 [ 0.10485845  2.22532741  0.02243766  0.07369059  2.10469478 -1.82913794\n",
      "  0.          0.        ]\n",
      "iteration 88 accepted 6.957718305854282 [ 0.08868279  2.29326645  0.02243766  0.07369059  1.95493682 -1.58616488\n",
      "  0.          0.        ]\n",
      "iteration 89 accepted 6.949855676140824 [ 0.06252227  2.29678347  0.02243766  0.07369059  1.87265184 -1.55136437\n",
      "  0.          0.        ]\n",
      "iteration 90 failed 6.949855676140821 [ 0.06252227  2.29678347  0.02243766  0.07369059  1.87265184 -1.55136437\n",
      "  0.          0.        ]\n",
      "iteration 91 failed 6.949855676140821 [ 0.06252227  2.29678347  0.02243766  0.07369059  1.87265184 -1.55136437\n",
      "  0.          0.        ]\n",
      "iteration 92 failed 6.949855676140821 [ 0.06252227  2.29678347  0.02243766  0.07369059  1.87265184 -1.55136437\n",
      "  0.          0.        ]\n",
      "iteration 93 accepted 6.949302484937161 [ 0.04775554  2.30764797  0.02243766  0.07369059  1.85349048 -1.54026116\n",
      "  0.          0.        ]\n",
      "iteration 94 accepted 6.929347763664655 [ 0.05914241  2.27740344  0.02243766  0.07369059  1.6919084  -1.39173017\n",
      "  0.          0.        ]\n",
      "iteration 95 failed 6.929347763664652 [ 0.05914241  2.27740344  0.02243766  0.07369059  1.6919084  -1.39173017\n",
      "  0.          0.        ]\n",
      "iteration 96 failed 6.929347763664652 [ 0.05914241  2.27740344  0.02243766  0.07369059  1.6919084  -1.39173017\n",
      "  0.          0.        ]\n",
      "iteration 97 converged 6.92934217020043 [ 0.05977834  2.27676257  0.02243766  0.07369059  1.69250771 -1.39252886\n",
      "  0.          0.        ]\n",
      "*** Fitted my_performance in 20.71675729751587s ***\n"
     ]
    }
   ],
   "source": [
    "def on_iteration(iteration_count, xs, us, J_opt, accepted, converged):\n",
    "    info = \"converged\" if converged else (\"accepted\" if accepted else \"failed\")\n",
    "    print(\"iteration\", iteration_count, info, J_opt, xs[-1])\n",
    "\n",
    "costs = {k: make_reacher_cost(k) for k in dynamics.keys()}\n",
    "ilqrs = {k: iLQR(dyn, costs[k], N) for k, dyn in dynamics.items()}\n",
    "xs = {}\n",
    "us = {}\n",
    "print(ilqrs.keys())\n",
    "for k, ilqr in ilqrs.items():\n",
    "    start = time.time()\n",
    "    print('*** Fitting {} ***'.format(k))\n",
    "    x0 = x0s[k]\n",
    "    xs[k], us[k] = ilqr.fit(x0, us_init, n_iterations=100, on_iteration=on_iteration)\n",
    "    end = time.time()\n",
    "    print('*** Fitted {} in {}s ***'.format(k, end - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = {k: dyn.f_u(x0s[k], us_init[0], 0) for k, dyn in dynamics.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res['my_performance']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res['my_basic']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Receding horizon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ilqr.controller import RecedingHorizonController\n",
    "\n",
    "def receding(underlying):\n",
    "    k = 'receding_' + underlying\n",
    "    dynamics[k] = dynamics[underlying]\n",
    "    x0s[k] = x0s[underlying]\n",
    "    controller = RecedingHorizonController(x0s[k], ilqrs[underlying])\n",
    "    rew = []\n",
    "    xs[k] = []\n",
    "    us[k] = []\n",
    "    for x, u in controller.control(us_init, subsequent_n_iterations=10):\n",
    "        ob, r, done, info = env.step(u)\n",
    "        xs[k].append(x)\n",
    "        us[k].append(u)\n",
    "        rew.append(r)\n",
    "        print('iteration', len(rew), r, x, u)\n",
    "        if len(rew) == N:\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "receding('my_basic')\n",
    "receding('my_performance')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Rollouts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "def rollout(env, dynamics, x0, us, render=False):\n",
    "    dynamics.set_state(x0)\n",
    "    if render:\n",
    "        env.render()\n",
    "    rew = []\n",
    "    actual_xs = []\n",
    "    for u in us:\n",
    "        _obs, r, done, info = env.step(u)\n",
    "        rew.append(r)\n",
    "        actual_xs.append(dynamics.get_state())\n",
    "        assert not done\n",
    "        if render:\n",
    "            env.render()\n",
    "            time.sleep(0.02)\n",
    "    return rew, actual_xs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "my_basic\n",
      "my_performance\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rewards</th>\n",
       "      <th>lengths</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>my_basic</th>\n",
       "      <td>-12.291561</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>my_performance</th>\n",
       "      <td>-7.492515</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  rewards  lengths\n",
       "my_basic       -12.291561      100\n",
       "my_performance  -7.492515      100"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rews = {}\n",
    "actual_xs = {}\n",
    "for k, solved_us in us.items():\n",
    "    print(k)\n",
    "    rews[k], actual_xs[k] = rollout(env.unwrapped, dynamics[k], x0s[k], solved_us, render=False)\n",
    "rewards = {k: sum(r) for k, r in rews.items()}\n",
    "lengths = {k: len(r) for k, r in rews.items()}\n",
    "pd.DataFrame({'rewards': rewards, 'lengths': lengths})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
